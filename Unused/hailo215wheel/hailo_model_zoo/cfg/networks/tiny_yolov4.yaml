base:
- base/yolo.yaml
preprocessing:
  input_shape: null
  meta_arch: mobilenet_ssd_ar
postprocessing:
  nms_iou_thresh: 0.3
  score_threshold: 0.1
  meta_arch: yolo_v3
  anchors:
    strides:
    - 32
    - 16
    sizes:
    - - 81
      - 82
      - 135
      - 169
      - 344
      - 319
    - - 23
      - 27
      - 37
      - 58
      - 81
      - 82
quantization:
  calib_set:
  - models_files/coco/2021-06-18/coco_calib2017.tfrecord
network:
  network_name: tiny_yolov4
paths:
  alls_script: tiny_yolov4.alls
  network_path:
  - models_files/ObjectDetection/Detection-COCO/yolo/tiny_yolov4/pretrained/2023-07-18/yolov4-tiny.tflite
  url: https://hailo-model-zoo.s3.eu-west-2.amazonaws.com/ObjectDetection/Detection-COCO/yolo/tiny_yolov4/pretrained/2023-07-18/tiny_yolov4.zip
parser:
  nodes:
  - detector/yolo-v4-tiny/Pad
  - - detector/yolo-v4-tiny/Conv_17/BiasAdd
    - detector/yolo-v4-tiny/Conv_20/BiasAdd
  normalization_params:
    fold_normalization: true
info:
  task: object detection
  input_shape: 416x416x3
  output_shape: 13x13x255, 26x26x255
  operations: 6.92G
  parameters: 6.05M
  framework: pytorch
  training_data: coco train2017
  validation_data: coco val2017
  eval_metric: mAP
  full_precision_result: 19.18
  source: https://github.com/Tianxiaomo/pytorch-YOLOv4
  license_url: https://www.apache.org/licenses/LICENSE-2.0
  license_name: Apache-2.0
