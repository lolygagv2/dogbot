normalization1 = normalization([0.0, 0.0, 0.0], [255.0, 255.0, 255.0])
model_optimization_config(calibration, batch_size=2, calibset_size=64)
model_optimization_flavor(compression_level=2)
pre_quantization_optimization(ew_add_fusing, policy=enabled, infusible_ew_add_type=conv)
post_quantization_optimization(finetune, policy=enabled, dataset_size=8192, epochs=8)
quantization_param(output_layer1, precision_mode=a16_w16)
quantization_param(output_layer2, precision_mode=a16_w16)
quantization_param(output_layer3, precision_mode=a16_w16)
model_optimization_config(globals, output_encoding_vector=enabled)