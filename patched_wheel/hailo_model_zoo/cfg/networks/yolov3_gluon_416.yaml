base:
- base/yolo.yaml
postprocessing:
  anchors:
    sizes:
    - - 10
      - 13
      - 16
      - 30
      - 33
      - 23
    - - 30
      - 61
      - 62
      - 45
      - 59
      - 119
    - - 116
      - 90
      - 156
      - 198
      - 373
      - 326
  meta_arch: yolo_v3
preprocessing:
  input_shape:
  - 416
  - 416
  - 3
  meta_arch: yolo_v3
network:
  network_name: yolov3_gluon_416
paths:
  alls_script: yolov3_gluon_416.alls
  network_path:
  - models_files/ObjectDetection/Detection-COCO/yolo/yolov3_gluon_416/pretrained/2023-07-18/yolov3.tflite
  url: https://hailo-model-zoo.s3.eu-west-2.amazonaws.com/ObjectDetection/Detection-COCO/yolo/yolov3_gluon_416/pretrained/2023-07-18/yolov3_gluon_416.zip
parser:
  nodes:
  - zero_padding2d/Pad
  - - yolov30_yolooutputv32_conv0/BiasAdd
    - yolov30_yolooutputv31_conv0/BiasAdd
    - yolov30_yolooutputv30_conv0/BiasAdd
  normalization_params:
    std_list:
    - 58.395
    - 57.12
    - 57.375
    normalize_in_net: true
    mean_list:
    - 123.675
    - 116.28
    - 103.53
info:
  task: object detection
  input_shape: 416x416x3
  output_shape: 13x13x255, 26x26x255, 52x52x255
  operations: 65.94G
  parameters: 61.92M
  framework: gluoncv
  training_data: coco train2017
  validation_data: coco val2017
  eval_metric: mAP
  full_precision_result: 36.28
  source: https://cv.gluon.ai/model_zoo/detection.html
  license_url: https://www.apache.org/licenses/LICENSE-2.0
  license_name: Apache-2.0
