#!/usr/bin/env python3
"""
Test script for FIXED 3-Stage AI Pipeline
Tests the working HEF direct API approach
"""

import sys
import os
import time
import cv2
import numpy as np
from pathlib import Path

# Add project root to path
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from core.ai_controller_3stage_fixed import AI3StageControllerFixed

def test_pipeline_structure():
    """Test the 3-stage pipeline structure without camera"""
    print("üß™ Testing 3-Stage Pipeline Structure")
    print("=" * 50)

    # Initialize AI controller
    ai = AI3StageControllerFixed()

    if not ai.initialize():
        print("‚ùå Failed to initialize AI controller")
        return False

    print(f"‚úÖ AI Controller initialized")
    status = ai.get_status()
    for key, value in status.items():
        print(f"   {key}: {value}")

    # Create test frame (simulated 4K)
    test_frame = np.zeros((1080, 1920, 3), dtype=np.uint8)
    # Add some pattern
    test_frame[400:680, 800:1120] = [100, 150, 200]  # Mock "dog" region

    print(f"\nüì∑ Testing with mock frame: {test_frame.shape}")

    # Test processing
    start_time = time.time()
    detections, poses, behaviors = ai.process_frame(test_frame)
    process_time = time.time() - start_time

    print(f"‚úÖ Pipeline processing completed in {process_time*1000:.1f}ms")
    print(f"   Detections: {len(detections)}")
    print(f"   Poses: {len(poses)}")
    print(f"   Behaviors: {len(behaviors)}")

    # Test multiple frames to build behavior history
    print(f"\nüîÑ Testing temporal behavior analysis...")
    for i in range(10):
        detections, poses, behaviors = ai.process_frame(test_frame)
        print(f"Frame {i+1}: {len(detections)} det, {len(poses)} poses, {len(behaviors)} behaviors")

        if behaviors:
            for behavior in behaviors:
                print(f"   Behavior: {behavior.behavior} (conf={behavior.confidence:.2f})")

    ai.cleanup()
    return True

def test_with_camera_if_available():
    """Test with camera if available"""
    print("\nüìπ Testing with Camera (if available)")
    print("=" * 50)

    # Initialize AI controller
    ai = AI3StageControllerFixed()
    if not ai.initialize():
        print("‚ùå AI Controller failed to initialize")
        return False

    # Try to open camera
    cap = None
    for camera_index in [0, 1, 2]:
        try:
            cap = cv2.VideoCapture(camera_index)
            if cap.isOpened():
                print(f"‚úÖ Camera found at index {camera_index}")
                break
            else:
                cap.release()
                cap = None
        except:
            continue

    if cap is None:
        print("‚ö†Ô∏è No camera available, skipping camera test")
        ai.cleanup()
        return True

    try:
        # Set camera resolution
        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1920)
        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 1080)

        actual_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        actual_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        fps = cap.get(cv2.CAP_PROP_FPS)

        print(f"üì∑ Camera: {actual_width}x{actual_height} @ {fps:.1f}fps")

        # Test a few frames
        frame_count = 0
        total_time = 0

        print("\nüé¨ Processing camera frames (testing 10 frames)...")

        while frame_count < 10:
            ret, frame = cap.read()
            if not ret:
                print("‚ùå Failed to read camera frame")
                break

            start_time = time.time()
            detections, poses, behaviors = ai.process_frame(frame)
            process_time = time.time() - start_time

            total_time += process_time
            frame_count += 1

            print(f"[{frame_count:02d}] "
                  f"Det: {len(detections)} | "
                  f"Poses: {len(poses)} | "
                  f"Behaviors: {len(behaviors)} | "
                  f"Time: {process_time*1000:.1f}ms")

            # Save debug frame occasionally
            if frame_count % 5 == 0:
                debug_filename = f"debug_3stage_frame_{frame_count:02d}.jpg"
                save_debug_frame(frame, detections, poses, debug_filename)

        if frame_count > 0:
            avg_time = total_time / frame_count
            avg_fps = 1.0 / avg_time if avg_time > 0 else 0
            print(f"\nüìä Performance: {avg_time*1000:.1f}ms avg, {avg_fps:.1f} FPS avg")

    except Exception as e:
        print(f"‚ùå Camera test error: {e}")

    finally:
        if cap:
            cap.release()
        ai.cleanup()

    return True

def save_debug_frame(frame, detections, poses, filename):
    """Save frame with detection/pose overlays for debugging"""
    try:
        debug_frame = frame.copy()

        # Draw detections
        for i, det in enumerate(detections):
            cv2.rectangle(debug_frame, (det.x1, det.y1), (det.x2, det.y2), (0, 255, 0), 2)
            cv2.putText(debug_frame, f"Dog {i+1}: {det.confidence:.2f}",
                       (det.x1, det.y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)

        # Draw pose keypoints (scaled to frame)
        for pose_idx, pose in enumerate(poses):
            keypoints = pose.keypoints
            det = pose.detection

            # Scale keypoints from 640x640 to detection box
            scale_x = det.width / 640
            scale_y = det.height / 640

            for kpt_idx, (x, y, conf) in enumerate(keypoints):
                if conf > 0.5:  # Only draw confident keypoints
                    # Scale and translate to detection box
                    x_px = int(det.x1 + x * scale_x)
                    y_px = int(det.y1 + y * scale_y)

                    # Draw keypoint
                    cv2.circle(debug_frame, (x_px, y_px), 3, (0, 0, 255), -1)

                    # Draw keypoint number for first few keypoints
                    if kpt_idx < 8:
                        cv2.putText(debug_frame, str(kpt_idx), (x_px+5, y_px-5),
                                   cv2.FONT_HERSHEY_SIMPLEX, 0.3, (255, 255, 255), 1)

        # Save to debug directory
        debug_dir = Path("debug_3stage")
        debug_dir.mkdir(exist_ok=True)

        cv2.imwrite(str(debug_dir / filename), debug_frame)
        print(f"üíæ Saved: {debug_dir / filename}")

    except Exception as e:
        print(f"Warning: Could not save debug frame: {e}")

def main():
    print("ü§ñ TreatSensei 3-Stage AI Pipeline Test - FIXED VERSION")
    print("Using working HEF direct API")
    print("=" * 60)

    success = True

    # Test 1: Pipeline structure without camera
    if not test_pipeline_structure():
        print("‚ùå Pipeline structure test failed")
        success = False

    # Test 2: Camera test if available
    if not test_with_camera_if_available():
        print("‚ùå Camera test failed")
        success = False

    print("\n" + "=" * 60)
    if success:
        print("‚úÖ All tests completed successfully!")
        print("\nüìã Summary:")
        print("- 3-stage pipeline structure working")
        print("- HEF models load successfully")
        print("- RGB color format implemented")
        print("- 640x640 processing confirmed")
        print("- Mock detections and poses generated")
        print("\nüöÄ Next steps:")
        print("- Implement actual HEF inference")
        print("- Parse YOLO detection outputs")
        print("- Parse YOLO pose outputs (9 tensors)")
        print("- Test with real dogs!")
    else:
        print("‚ùå Some tests failed!")

    print(f"\nüìÅ Debug frames saved to: debug_3stage/")

if __name__ == "__main__":
    main()